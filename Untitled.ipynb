{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'osgeo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31334a7b22fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'osgeo'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from osgeo import gdal\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "\n",
    "# A list of \"random\" colors (for a nicer output)\n",
    "COLORS = [\"#000000\", \"#FFFF00\", \"#1CE6FF\", \"#FF34FF\", \"#FF4A46\", \"#008941\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define some useful functions that we are going to be using later. They are making heavy use of the GDAL api to manipulate raster and vector data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask_from_vector(vector_data_path, cols, rows, geo_transform, projection, target_value=1):\n",
    "    \"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\"\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[target_value])\n",
    "    return target_ds\n",
    "def vectors_to_raster(file_paths, rows, cols, geo_transform, projection):\n",
    "    \"\"\"Rasterize all the vectors in the given directory into a single image.\"\"\"\n",
    "    labeled_pixels = np.zeros((rows, cols))\n",
    "    for i, path in enumerate(file_paths):\n",
    "        label = i+1\n",
    "        ds = create_mask_from_vector(path, cols, rows, geo_transform, projection, target_value=label)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        labeled_pixels += band.ReadAsArray()\n",
    "        ds = None     \n",
    "    return labeled_pixels\n",
    "def write_geotiff(fname, data, geo_transform, projection):\n",
    "    \"\"\"Create a GeoTIFF file with the given data.\"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    dataset = None  # Close the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_data_path = \"5bandsImage.tif\"\n",
    "#raster_data_path = \"7040/PixelAggregate/Resolution0.01/5bandsFINALImage.tif\"\n",
    "#output_fname = \"classification.tiff\"\n",
    "train_data_path = \"ROITraining/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now, we will use the GDAL api to read the input GeoTiff: extract the geographic information and transform the bandâ€™s data into a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2a20e14d3f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraster_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGA_ReadOnly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeo_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraster_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraster_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetProjectionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbands_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraster_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRasterCount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdal' is not defined"
     ]
    }
   ],
   "source": [
    "raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n",
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "bands_data = []\n",
    "for b in range(1, raster_dataset.RasterCount+1):\n",
    "    band = raster_dataset.GetRasterBand(b)\n",
    "    bands_data.append(band.ReadAsArray())\n",
    "\n",
    "bands_data = np.dstack(bands_data)\n",
    "rows, cols, n_bands = bands_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the training data: project all the vector data, in the training dataset, into a numpy array. Each class is assigned a label (a number between 1 and the total number of classes). If the value v in the position (i, j) of this new array is not zero, that means that the pixel (i, j) must be used as a training sample of class v.\n",
    "# training_samples is the list of pixels to be used for training. In our case, a pixel is a point in the 7-dimensional space of the bands.\n",
    "# training_labels is a list of class labels such that the i-th position indicates the class for i-th pixel in training_samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-884590bc0157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshapefiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabeled_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors_to_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapefiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mis_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeled_pixels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir(train_data_path) if f.endswith('.shp')]\n",
    "classes = [f.split('.')[0] for f in files]\n",
    "shapefiles = [os.path.join(train_data_path, f) for f in files if f.endswith('.shp')]\n",
    "\n",
    "labeled_pixels = vectors_to_raster(shapefiles, rows, cols, geo_transform, proj)\n",
    "is_train = np.nonzero(labeled_pixels)\n",
    "training_labels = labeled_pixels[is_train]\n",
    "training_samples = bands_data[is_train]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##OOB Errors for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(warm_start=True, oob_score=True, max_features=\"sqrt\")\n",
    "\n",
    "#dict of (estimator, error_rate)\n",
    "error_rate = {}\n",
    "\n",
    "#explore max 200\n",
    "min_estimators = 10\n",
    "max_estimators = 100\n",
    "\n",
    "for i in range(min_estimators, max_estimators + 1):\n",
    "    clf.set_params(n_estimators=i)\n",
    "    clf.fit(training_samples, training_labels)\n",
    "    # Record the OOB error for each `n_estimators=i` setting.\n",
    "    oob_error = 1 - clf.oob_score_\n",
    "    error_rate[i] = oob_error\n",
    "    \n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "er = sorted(error_rate.items())\n",
    "x, y = zip(*er)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.show()\n",
    "#fig.savefig('7040/PixelAggregate/Resolution0.01/n1500.png', dpi = 300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
